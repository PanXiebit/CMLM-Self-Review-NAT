usage: train.py [-h] [--no-progress-bar] [--log-interval N] [--log-format {json,none,simple,tqdm}] [--tensorboard-logdir DIR] [--tbmf-wrapper] [--seed N] [--cpu] [--fp16]
                [--memory-efficient-fp16] [--fp16-init-scale FP16_INIT_SCALE] [--fp16-scale-window FP16_SCALE_WINDOW] [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]
                [--min-loss-scale D] [--threshold-loss-scale THRESHOLD_LOSS_SCALE] [--user-dir USER_DIR]
                [--criterion {cross_entropy,label_smoothed_cross_entropy,label_smoothed_length_cross_entropy,label_smoothed_length_gan_cross_entropy}]
                [--optimizer {adadelta,adafactor,adagrad,adam,lamb,nag,sgd}] [--lr-scheduler {cosine,fixed,inverse_sqrt,polynomial_decay,reduce_lr_on_plateau,triangular}]
                [--task TASK] [--num-workers N] [--skip-invalid-size-inputs-valid-test] [--max-tokens N] [--max-sentences N] [--required-batch-size-multiple N]
                [--dataset-impl FORMAT] [--train-subset SPLIT] [--valid-subset SPLIT] [--validate-interval N] [--disable-validation] [--max-tokens-valid N]
                [--max-sentences-valid N] [--curriculum N] [--distributed-world-size N] [--distributed-rank DISTRIBUTED_RANK] [--distributed-backend DISTRIBUTED_BACKEND]
                [--distributed-init-method DISTRIBUTED_INIT_METHOD] [--distributed-port DISTRIBUTED_PORT] [--device-id DEVICE_ID] [--distributed-no-spawn]
                [--ddp-backend {c10d,no_c10d}] [--bucket-cap-mb MB] [--fix-batches-to-gpus] [--find-unused-parameters] --arch ARCH [--max-epoch N] [--max-update N]
                [--clip-norm NORM] [--sentence-avg] [--update-freq N1,N2,...,N_K] [--lr LR_1,LR_2,...,LR_N] [--min-lr LR] [--use-bmuf] [--save-dir DIR]
                [--restore-file RESTORE_FILE] [--reset-dataloader] [--reset-lr-scheduler] [--reset-meters] [--reset-optimizer] [--optimizer-overrides DICT]
                [--save-interval N] [--save-interval-updates N] [--keep-interval-updates N] [--keep-last-epochs N] [--no-save] [--no-epoch-checkpoints]
                [--no-last-checkpoints] [--no-save-optimizer-state] [--best-checkpoint-metric BEST_CHECKPOINT_METRIC] [--maximize-best-checkpoint-metric] [--dropout D]
                [--attention-dropout D] [--relu-dropout D] [--encoder-embed-path STR] [--encoder-embed-dim N] [--encoder-ffn-embed-dim N] [--encoder-layers N]
                [--encoder-attention-heads N] [--encoder-normalize-before] [--encoder-learned-pos] [--decoder-embed-path STR] [--decoder-embed-dim N]
                [--decoder-ffn-embed-dim N] [--decoder-layers N] [--decoder-attention-heads N] [--decoder-learned-pos] [--decoder-normalize-before]
                [--no-enc-token-positional-embeddings] [--no-dec-token-positional-embeddings] [--embedding-only] [--share-decoder-input-output-embed]
                [--share-all-embeddings] [--share_gen_dec_embedding] [--share_gen_dec_all_weights] [--share_gen_dec_encoder_weights] [--dis_weight DIS_WEIGHT]
                [--temperature TEMPERATURE] [--adaptive-softmax-cutoff EXPR] [--adaptive-softmax-dropout D] [--bilm-model-dropout D] [--bilm-attention-dropout D]
                [--bilm-relu-dropout D] [--bilm-mask-last-state] [--bilm-add-bos] [--decoder-embed-scale DECODER_EMBED_SCALE] [--encoder-embed-scale ENCODER_EMBED_SCALE]
                [--label-smoothing D] [--gen_weights D] [--dis_weights D] [--adam-betas B] [--adam-eps D] [--weight-decay WD] [--warmup-updates N] [--warmup-init-lr LR]
                [-s SRC] [-t TARGET] [--raw-text] [--left-pad-source BOOL] [--left-pad-target BOOL] [--max-source-positions N] [--max-target-positions N]
                [--upsample-primary UPSAMPLE_PRIMARY] [--self-target] [--dynamic-length] [--mask-range]
                data [data ...]
train.py: error: unrecognized arguments: #
